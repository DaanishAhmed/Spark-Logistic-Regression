{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Low Birth Weight Cases for Newborn Babies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Source: Hosmer, D.W., Lemeshow, S. and Sturdivant, R.X. (2013) Applied Logistic Regression, 3rd ed., New York: Wiley\n",
    "\n",
    "This dataset is also part of the aplore3 R package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Load Libraries](#load_libraries)\n",
    "- [Access Data](#access_data)\n",
    "- [Split Data into Training and Test Set](#training_test)\n",
    "- [Build Logistic Regression Model](#build_model)\n",
    "- [Logistic Regression Predictions for Test Data](#test_data)\n",
    "- [Evaluate Logistic Regression Model](#evaluate_model)\n",
    "- [Build Naive Bayes Model](#build_model_2)\n",
    "- [Naive Bayes Predictions for Test Data](#test_data_2)\n",
    "- [Evaluate Naive Bayes Model](#evaluate_model_2)\n",
    "- [Build Decision Tree Model](#build_model_3)\n",
    "- [Decision Tree Predictions for Test Data](#test_data_3)\n",
    "- [Evaluate Decision Tree Model](#evaluate_model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load_libraries\"></a>\n",
    "## Load Libraries\n",
    "\n",
    "The Spark and Python libraries that you need are preinstalled in the notebook environment and only need to be loaded.\n",
    "\n",
    "Run the following cell to load the libraries you will work with in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark Machine Learning Library\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, NaiveBayes, MultilayerPerceptronClassifier, DecisionTreeClassifier\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql import Row, SQLContext\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from numpy import array\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# Library for confusion matrix, precision, test error\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "# Library For Area under ROC curve and Area under precision-recall curve\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "# Assign resources to the application\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data will be loaded into an array.\n",
    "# This is the summary of the data structure, including the column position and name.\n",
    "# The first filed starts from position 0. \n",
    "\n",
    "# 0 ID      -  Identification code\n",
    "# 1 LOW     -  Low birth weight (0: >= 2500 g, 1: < 2500 g), target variable\n",
    "# 2 AGE     -  Mother's age in years\n",
    "# 3 RACE    -  Race (1: White, 2: Black, 3: Other)\n",
    "# 4 SMOKE   -  Smoking status during pregnancy (1: No, 2: Yes)\n",
    "# 5 PTL     -  History of premature labor (1: None, 2: One, 3: Two, etc)\n",
    "# 6 HT      -  History of hypertension (1: No, 2: Yes)\n",
    "# 7 UI      -  Presence of Uterine irritability (1: No, 2: Yes)\n",
    "# 8 FTV     -  Number of physician visits during the first trimester (1: None, 2: One, 3: Two, etc)\n",
    "\n",
    "# Label is a target variable. PersonInfo is a list of independent variables besides unique identifier\n",
    "\n",
    "LabeledDocument = Row(\"ID\", \"PersonInfo\", \"label\")\n",
    "\n",
    "# Define a function that parses the raw CSV file and returns an object of type LabeledDocument\n",
    "\n",
    "def parseDocument(line):\n",
    "    values = [str(x) for x in line.split(',')] \n",
    "    if (values[1]>'0'):\n",
    "      LOW = 1.0\n",
    "    else:\n",
    "      LOW = 0.0\n",
    "        \n",
    "    textValue = str(values[2]) + \" \" + str(values[3])+ \" \" + str(values[4]) + str(values[5])+ \" \" + str(values[6]) + str(values[7])+ \" \" + str(values[8])\n",
    "    return LabeledDocument(values[0], textValue, LOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"access_data\"></a>\n",
    "## Access Data\n",
    "Before you can access data in the data file in the Object Storage, you must setup the Spark configuration with your Object Storage credentials. \n",
    "\n",
    "To do this, click on the cell below and select the **Insert to code > Insert Spark Session DataFrame** function from the Files tab below the data file you want to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">The following code contains the credentials for a file in your IBM Cloud Object Storage. Delete the code starting from `from pyspark.sql import SparkSession` line before you run the cell.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object Storage Credentials\n",
    "import ibmos2spark\n",
    "\n",
    "# @hidden_cell\n",
    "credentials = {\n",
    "    'endpoint': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n",
    "    'api_key': 'lue6np0RwcvhARfJIQNtvVTUt3I45m5qk9UHM6LFTc3B',\n",
    "    'service_id': 'iam-ServiceId-3ac1bdb0-c8a1-4ae8-abe0-2dd53ae4c6e9',\n",
    "    'iam_service_endpoint': 'https://iam.ng.bluemix.net/oidc/token'}\n",
    "\n",
    "configuration_name = 'os_9d550c7f6655453f915511631f5b077f_configs'\n",
    "cos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the data into a `Spark RDD` and output the number of rows and first 5 rows.\n",
    "Each project you create has a bucket in your object storage. You can get the bucket name from the project Settings page. Change the string `BUCKET` to the bucket name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in the data set: 190\n",
      "The first 5 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'ID,LOW,AGE,RACE,SMOKE,PTL,HT,UI,FTV',\n",
       " u'85,0,19,2,0,0,0,1,0',\n",
       " u'86,0,33,3,0,0,0,0,3',\n",
       " u'87,0,20,1,1,0,0,0,1',\n",
       " u'88,0,21,1,1,0,0,1,2']"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.textFile(cos.url('lowbwt.csv', 'assignment331c5c83422a7434ab113135bf62f5fb0'))\n",
    "print \"Total records in the data set:\", data.count()\n",
    "print \"The first 5 rows\"\n",
    "data.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crate DataFrame from RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 190\n",
      "First 5 records: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(ID=u'ID', PersonInfo=u'AGE RACE SMOKEPTL HTUI FTV', label=1.0),\n",
       " Row(ID=u'85', PersonInfo=u'19 2 00 01 0', label=0.0),\n",
       " Row(ID=u'86', PersonInfo=u'33 3 00 00 3', label=0.0),\n",
       " Row(ID=u'87', PersonInfo=u'20 1 10 00 1', label=0.0),\n",
       " Row(ID=u'88', PersonInfo=u'21 1 10 01 2', label=0.0)]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data into a dataframe, parse it using the function above\n",
    "documents = data.filter(lambda s: \"Name\" not in s).map(parseDocument)\n",
    "lowbwtData = documents.toDF() # ToDataFrame\n",
    "print \"Number of records: \" + str(lowbwtData.count())\n",
    "print \"First 5 records: \"\n",
    "lowbwtData.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"training_test\"></a>\n",
    "## Split Data into Training and Test Set\n",
    "\n",
    "We divide the data into training and test set.  The training set is used to build the model to be used on future data, and the test set is used to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in the training set: 114\n",
      "Number of records in the test set: 76\n",
      "First 20 records in the training set: \n",
      "+---+------------+-----+\n",
      "| ID|  PersonInfo|label|\n",
      "+---+------------+-----+\n",
      "|100|18 1 10 00 0|  0.0|\n",
      "|104|20 3 00 01 0|  0.0|\n",
      "|105|28 1 10 00 1|  0.0|\n",
      "|106|32 3 00 00 2|  0.0|\n",
      "|107|31 1 00 01 3|  0.0|\n",
      "|109|28 3 00 00 0|  0.0|\n",
      "|112|28 1 00 00 0|  0.0|\n",
      "|113|17 1 10 00 0|  0.0|\n",
      "|114|29 1 00 00 2|  0.0|\n",
      "|115|26 2 10 00 0|  0.0|\n",
      "|119|35 2 11 00 1|  0.0|\n",
      "|120|25 1 00 00 1|  0.0|\n",
      "|123|29 1 10 00 2|  0.0|\n",
      "|124|19 1 10 00 2|  0.0|\n",
      "|127|33 1 10 00 1|  0.0|\n",
      "|128|21 2 10 00 2|  0.0|\n",
      "|130|23 2 00 00 1|  0.0|\n",
      "|132|18 1 10 01 0|  0.0|\n",
      "|133|18 1 10 01 0|  0.0|\n",
      "|135|19 3 00 00 0|  0.0|\n",
      "+---+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Divide the data into training and test set, with random seed to reproduce results\n",
    "(train, test) = lowbwtData.randomSplit([0.6, 0.4], seed = 123)\n",
    "print \"Number of records in the training set: \" + str(train.count())\n",
    "print \"Number of records in the test set: \" + str(test.count())\n",
    "# Output first 20 records in the training set\n",
    "print \"First 20 records in the training set: \"\n",
    "train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"build_model\"></a>\n",
    "## Build Logistic Regression Model\n",
    "\n",
    "We use the Pipeline of SparkML to build the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Logistic Regression using Pipeline of SparkML\n",
    "tokenizer = Tokenizer(inputCol=\"PersonInfo\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=50, regParam=0.001)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(262144, {8227: -0.8026, 18127: -1.8382, 18659: -2.7236, 24537: -0.3984, 31351: 3.2539, 37812: 4.4797, 64358: 2.2765, 69821: -3.0029, 83214: 0.0322, 89074: 1.4235, 98627: -3.8517, 109681: 0.3086, 110466: 8.547, 112272: 0.8523, 128319: 0.8382, 139093: 0.1271, 146429: -5.4366, 147946: -2.9156, 175329: -2.6536, 177493: 2.6024, 187043: 1.6197, 207020: -1.8509, 212053: 0.5704, 213217: -10.6018, 219381: -0.0939, 233878: -5.2583, 236232: -0.0424, 242525: -1.9885, 250051: -3.8739, 250733: -3.5146, 250802: 1.7828, 252551: -7.0663, 257339: 8.6457, 259362: 0.5064, 259523: 0.8185})"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up Logistic Regression Model\n",
    "# the stages are executed in order\n",
    "model = pipeline.fit(train)\n",
    "#[stage.coefficients for stage in model.stages if hasattr(stage, \"coefficients\")]\n",
    "# model.stages[2].intercept\n",
    "model.stages[2].coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test_data\"></a>\n",
    "## Logistic Regression Predictions for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(PersonInfo=u'18 1 10 00 0', prediction=0.0, probability=DenseVector([0.9974, 0.0026]))\n",
      "Row(PersonInfo=u'15 2 00 00 0', prediction=0.0, probability=DenseVector([0.9904, 0.0096]))\n",
      "Row(PersonInfo=u'25 1 10 00 3', prediction=1.0, probability=DenseVector([0.084, 0.916]))\n",
      "Row(PersonInfo=u'36 1 00 00 1', prediction=0.0, probability=DenseVector([0.9889, 0.0111]))\n",
      "Row(PersonInfo=u'25 3 00 01 2', prediction=1.0, probability=DenseVector([0.0458, 0.9542]))\n",
      "Row(PersonInfo=u'17 2 00 00 1', prediction=0.0, probability=DenseVector([0.8315, 0.1685]))\n",
      "Row(PersonInfo=u'17 2 00 00 1', prediction=0.0, probability=DenseVector([0.8315, 0.1685]))\n",
      "Row(PersonInfo=u'24 1 11 00 1', prediction=1.0, probability=DenseVector([0.0004, 0.9996]))\n",
      "Row(PersonInfo=u'25 2 00 00 0', prediction=0.0, probability=DenseVector([0.884, 0.116]))\n",
      "Row(PersonInfo=u'27 1 10 00 0', prediction=1.0, probability=DenseVector([0.0022, 0.9978]))\n",
      "Row(PersonInfo=u'31 1 10 00 2', prediction=0.0, probability=DenseVector([0.9817, 0.0183]))\n",
      "Row(PersonInfo=u'19 1 00 00 2', prediction=0.0, probability=DenseVector([0.9769, 0.0231]))\n",
      "Row(PersonInfo=u'21 1 00 00 0', prediction=0.0, probability=DenseVector([0.9965, 0.0035]))\n",
      "Row(PersonInfo=u'32 1 00 00 4', prediction=0.0, probability=DenseVector([1.0, 0.0]))\n",
      "Row(PersonInfo=u'22 3 10 00 0', prediction=0.0, probability=DenseVector([0.744, 0.256]))\n",
      "Row(PersonInfo=u'22 1 10 00 0', prediction=0.0, probability=DenseVector([0.9264, 0.0736]))\n",
      "Row(PersonInfo=u'19 3 00 00 0', prediction=0.0, probability=DenseVector([0.9747, 0.0253]))\n",
      "Row(PersonInfo=u'21 3 10 01 0', prediction=1.0, probability=DenseVector([0.187, 0.813]))\n",
      "Row(PersonInfo=u'30 3 00 00 0', prediction=0.0, probability=DenseVector([0.9995, 0.0005]))\n",
      "Row(PersonInfo=u'17 3 00 00 0', prediction=0.0, probability=DenseVector([0.8181, 0.1819]))\n",
      "Row(PersonInfo=u'23 3 00 00 2', prediction=1.0, probability=DenseVector([0.3, 0.7]))\n",
      "Row(PersonInfo=u'24 3 00 00 0', prediction=0.0, probability=DenseVector([0.8966, 0.1034]))\n",
      "Row(PersonInfo=u'28 1 00 00 0', prediction=0.0, probability=DenseVector([0.9997, 0.0003]))\n",
      "Row(PersonInfo=u'20 3 01 01 1', prediction=1.0, probability=DenseVector([0.0116, 0.9884]))\n",
      "Row(PersonInfo=u'31 3 10 00 2', prediction=0.0, probability=DenseVector([0.9252, 0.0748]))\n",
      "Row(PersonInfo=u'23 3 10 00 1', prediction=1.0, probability=DenseVector([0.0456, 0.9544]))\n",
      "Row(PersonInfo=u'18 2 00 00 0', prediction=0.0, probability=DenseVector([0.9997, 0.0003]))\n",
      "Row(PersonInfo=u'20 2 10 00 0', prediction=0.0, probability=DenseVector([0.5108, 0.4892]))\n",
      "Row(PersonInfo=u'23 1 00 00 0', prediction=0.0, probability=DenseVector([0.8799, 0.1201]))\n",
      "Row(PersonInfo=u'32 1 00 00 0', prediction=0.0, probability=DenseVector([1.0, 0.0]))\n",
      "Row(PersonInfo=u'23 3 00 00 0', prediction=0.0, probability=DenseVector([0.6285, 0.3715]))\n",
      "Row(PersonInfo=u'19 3 00 00 0', prediction=0.0, probability=DenseVector([0.9747, 0.0253]))\n",
      "Row(PersonInfo=u'36 1 00 00 0', prediction=0.0, probability=DenseVector([0.9948, 0.0052]))\n",
      "Row(PersonInfo=u'21 3 00 00 2', prediction=0.0, probability=DenseVector([0.943, 0.057]))\n",
      "Row(PersonInfo=u'19 1 10 10 0', prediction=1.0, probability=DenseVector([0.3786, 0.6214]))\n",
      "Row(PersonInfo=u'33 3 00 00 3', prediction=0.0, probability=DenseVector([0.9956, 0.0044]))\n",
      "Row(PersonInfo=u'20 1 10 00 1', prediction=1.0, probability=DenseVector([0.474, 0.526]))\n",
      "Row(PersonInfo=u'18 1 10 01 0', prediction=0.0, probability=DenseVector([0.9574, 0.0426]))\n",
      "Row(PersonInfo=u'22 1 00 00 1', prediction=0.0, probability=DenseVector([0.9898, 0.0102]))\n",
      "Row(PersonInfo=u'30 3 01 01 2', prediction=0.0, probability=DenseVector([0.6404, 0.3596]))\n",
      "Row(PersonInfo=u'AGE RACE SMOKEPTL HTUI FTV', prediction=0.0, probability=DenseVector([0.6044, 0.3956]))\n",
      "Row(PersonInfo=u'24 2 01 00 1', prediction=1.0, probability=DenseVector([0.3571, 0.6429]))\n",
      "Row(PersonInfo=u'16 1 10 00 0', prediction=0.0, probability=DenseVector([0.9939, 0.0061]))\n",
      "Row(PersonInfo=u'24 3 00 10 0', prediction=1.0, probability=DenseVector([0.3437, 0.6563]))\n",
      "Row(PersonInfo=u'30 1 00 00 1', prediction=0.0, probability=DenseVector([0.9998, 0.0002]))\n",
      "Row(PersonInfo=u'19 1 10 10 0', prediction=1.0, probability=DenseVector([0.3786, 0.6214]))\n",
      "Row(PersonInfo=u'24 3 01 00 0', prediction=1.0, probability=DenseVector([0.3361, 0.6639]))\n",
      "Row(PersonInfo=u'23 1 00 00 1', prediction=0.0, probability=DenseVector([0.7741, 0.2259]))\n",
      "Row(PersonInfo=u'30 1 00 00 1', prediction=0.0, probability=DenseVector([0.9998, 0.0002]))\n",
      "Row(PersonInfo=u'32 1 00 00 2', prediction=0.0, probability=DenseVector([0.9999, 0.0001]))\n",
      "Row(PersonInfo=u'28 3 00 00 1', prediction=0.0, probability=DenseVector([0.9976, 0.0024]))\n",
      "Row(PersonInfo=u'14 1 00 00 0', prediction=0.0, probability=DenseVector([0.9929, 0.0071]))\n",
      "Row(PersonInfo=u'25 1 00 00 2', prediction=0.0, probability=DenseVector([0.7808, 0.2192]))\n",
      "Row(PersonInfo=u'26 3 00 00 0', prediction=0.0, probability=DenseVector([0.9499, 0.0501]))\n",
      "Row(PersonInfo=u'32 1 10 00 0', prediction=0.0, probability=DenseVector([0.9996, 0.0004]))\n",
      "Row(PersonInfo=u'22 1 00 00 0', prediction=0.0, probability=DenseVector([0.9952, 0.0048]))\n",
      "Row(PersonInfo=u'31 1 00 00 2', prediction=0.0, probability=DenseVector([0.9989, 0.0011]))\n",
      "Row(PersonInfo=u'25 3 00 00 0', prediction=0.0, probability=DenseVector([0.7645, 0.2355]))\n",
      "Row(PersonInfo=u'16 3 00 00 1', prediction=0.0, probability=DenseVector([0.9966, 0.0034]))\n",
      "Row(PersonInfo=u'21 3 00 00 0', prediction=0.0, probability=DenseVector([0.9849, 0.0151]))\n",
      "Row(PersonInfo=u'19 1 00 00 2', prediction=0.0, probability=DenseVector([0.9769, 0.0231]))\n",
      "Row(PersonInfo=u'24 1 00 00 0', prediction=0.0, probability=DenseVector([0.9741, 0.0259]))\n",
      "Row(PersonInfo=u'28 3 11 01 0', prediction=1.0, probability=DenseVector([0.0012, 0.9988]))\n",
      "Row(PersonInfo=u'27 2 00 01 0', prediction=1.0, probability=DenseVector([0.0012, 0.9988]))\n",
      "Row(PersonInfo=u'20 3 10 01 0', prediction=1.0, probability=DenseVector([0.0253, 0.9747]))\n",
      "Row(PersonInfo=u'25 3 01 00 1', prediction=1.0, probability=DenseVector([0.0814, 0.9186]))\n",
      "Row(PersonInfo=u'18 3 00 00 0', prediction=0.0, probability=DenseVector([0.9993, 0.0007]))\n",
      "Row(PersonInfo=u'21 3 01 00 4', prediction=0.0, probability=DenseVector([0.997, 0.003]))\n",
      "Row(PersonInfo=u'26 3 00 00 0', prediction=0.0, probability=DenseVector([0.9499, 0.0501]))\n",
      "Row(PersonInfo=u'15 1 00 00 0', prediction=0.0, probability=DenseVector([0.9948, 0.0052]))\n",
      "Row(PersonInfo=u'20 2 10 00 0', prediction=0.0, probability=DenseVector([0.5108, 0.4892]))\n",
      "Row(PersonInfo=u'15 3 00 01 0', prediction=0.0, probability=DenseVector([0.7189, 0.2811]))\n",
      "Row(PersonInfo=u'30 1 11 00 0', prediction=1.0, probability=DenseVector([0.177, 0.823]))\n",
      "Row(PersonInfo=u'26 3 01 10 1', prediction=1.0, probability=DenseVector([0.0303, 0.9697]))\n",
      "Row(PersonInfo=u'28 1 10 00 2', prediction=0.0, probability=DenseVector([0.9832, 0.0168]))\n",
      "Row(PersonInfo=u'14 3 00 00 2', prediction=0.0, probability=DenseVector([0.8907, 0.1093]))\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test documents and print columns of interest\n",
    "prediction = model.transform(test)\n",
    "selected = prediction.select(\"PersonInfo\", \"prediction\", \"probability\")\n",
    "for row in selected.collect():\n",
    "    print row\n",
    "#for row in prediction.collect():\n",
    "#    print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|0.0       |56   |\n",
      "|1.0       |20   |\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tabulate the predicted outcome\n",
    "prediction.select(\"prediction\").groupBy(\"prediction\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|0.0  |53   |\n",
      "|1.0  |23   |\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tabulate the actual outcome\n",
    "prediction.select(\"label\").groupBy(\"label\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---+---+\n",
      "|label_prediction|0.0|1.0|\n",
      "+----------------+---+---+\n",
      "|             1.0| 15|  8|\n",
      "|             0.0| 41| 12|\n",
      "+----------------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This table shows:\n",
    "# 1. The number of low birth weight infants predicted as having low birth weight\n",
    "# 2. The number of low birth weight infants predicted as not having low birth weight\n",
    "# 3. The number of regular birth weight infants predicted as having low birth weight\n",
    "# 4. The number of regular birth weight infants predicted as not having low birth weight\n",
    "\n",
    "prediction.crosstab('label', 'prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluate_model\"></a>\n",
    "## Evaluate Logistic Regression Model\n",
    "\n",
    "We evaluate the model on a training set and on a test set.  The purpose is to measure the model's predictive accuracy, including the accuracy for new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Measure = 0.782608695652\n",
      "Training Accuracy = 0.868421052632\n",
      "Training Error = 0.131578947368\n",
      "Precision = 0.84375\n",
      "Recall = 0.72972972973\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Logistic Regression model on a training set\n",
    "# Select (prediction, true label) and compute training error\n",
    "pred_lr=model.transform(train).select(\"prediction\", \"label\")\n",
    "eval_lr=MulticlassClassificationEvaluator (\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_lr=eval_lr.evaluate(pred_lr)\n",
    "# create RDD\n",
    "predictionAndLabels_lr=pred_lr.rdd\n",
    "metrics_lr=MulticlassMetrics(predictionAndLabels_lr)\n",
    "precision_lr=metrics_lr.precision(1.0)\n",
    "recall_lr=metrics_lr.recall(1.0)\n",
    "f1Measure_lr = metrics_lr.fMeasure(1.0, 1.0)\n",
    "print(\"F1 Measure = %s\" % f1Measure_lr)\n",
    "print (\"Training Accuracy = %s\" %accuracy_lr)\n",
    "print (\"Training Error = %s\" % (1-accuracy_lr))\n",
    "print (\"Precision = %s\" %precision_lr)\n",
    "print (\"Recall = %s\" %recall_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Measure = 0.372093023256\n",
      "Test Accuracy = 0.644736842105\n",
      "Test Error = 0.355263157895\n",
      "Precision = 0.4\n",
      "Recall = 0.347826086957\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Logistic Regression model on a test set\n",
    "# Select (prediction, true label) and compute test error\n",
    "pred_lr=model.transform(test).select(\"prediction\", \"label\")\n",
    "eval_lr=MulticlassClassificationEvaluator (\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_lr=eval_lr.evaluate(pred_lr)\n",
    "# create RDD\n",
    "predictionAndLabels_lr=pred_lr.rdd\n",
    "metrics_lr=MulticlassMetrics(predictionAndLabels_lr)\n",
    "precision_lr=metrics_lr.precision(1.0)\n",
    "recall_lr=metrics_lr.recall(1.0)\n",
    "f1Measure_lr = metrics_lr.fMeasure(1.0, 1.0)\n",
    "print(\"F1 Measure = %s\" % f1Measure_lr)\n",
    "print (\"Test Accuracy = %s\" %accuracy_lr)\n",
    "print (\"Test Error = %s\" % (1-accuracy_lr))\n",
    "print (\"Precision = %s\" %precision_lr)\n",
    "print (\"Recall = %s\" %recall_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under PR = 0.472597254005\n",
      "Area under ROC = 0.560705496308\n"
     ]
    }
   ],
   "source": [
    "bin_lr=BinaryClassificationMetrics(predictionAndLabels_lr)\n",
    "\n",
    "# Area under precision-recall curve\n",
    "print(\"Area under PR = %s\" % bin_lr.areaUnderPR)\n",
    "# Area under precision-recall curve\n",
    "print(\"Area under ROC = %s\" % bin_lr.areaUnderROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"build_model_2\"></a>\n",
    "## Build Naive Bayes Model\n",
    "\n",
    "We use the Pipeline of SparkML to build the Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Naive Bayes using Pipeline of SparkML\n",
    "tokenizer = Tokenizer(inputCol=\"PersonInfo\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\", numFeatures=32)\n",
    "nb = NaiveBayes(labelCol=\"label\", featuresCol=\"features\", predictionCol=\"prediction\", smoothing=1.0, modelType=\"multinomial\")\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Naive Bayes Model\n",
    "# the stages are executed in order\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test_data_2\"></a>\n",
    "## Naive Bayes Predictions for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(PersonInfo=u'18 1 10 00 0', prediction=0.0, probability=DenseVector([0.8637, 0.1363]))\n",
      "Row(PersonInfo=u'15 2 00 00 0', prediction=0.0, probability=DenseVector([0.7652, 0.2348]))\n",
      "Row(PersonInfo=u'25 1 10 00 3', prediction=0.0, probability=DenseVector([0.7839, 0.2161]))\n",
      "Row(PersonInfo=u'36 1 00 00 1', prediction=0.0, probability=DenseVector([0.8827, 0.1173]))\n",
      "Row(PersonInfo=u'25 3 00 01 2', prediction=0.0, probability=DenseVector([0.6153, 0.3847]))\n",
      "Row(PersonInfo=u'17 2 00 00 1', prediction=0.0, probability=DenseVector([0.8209, 0.1791]))\n",
      "Row(PersonInfo=u'17 2 00 00 1', prediction=0.0, probability=DenseVector([0.8209, 0.1791]))\n",
      "Row(PersonInfo=u'24 1 11 00 1', prediction=0.0, probability=DenseVector([0.5169, 0.4831]))\n",
      "Row(PersonInfo=u'25 2 00 00 0', prediction=0.0, probability=DenseVector([0.8697, 0.1303]))\n",
      "Row(PersonInfo=u'27 1 10 00 0', prediction=0.0, probability=DenseVector([0.6788, 0.3212]))\n",
      "Row(PersonInfo=u'31 1 10 00 2', prediction=0.0, probability=DenseVector([0.7228, 0.2772]))\n",
      "Row(PersonInfo=u'19 1 00 00 2', prediction=0.0, probability=DenseVector([0.9185, 0.0815]))\n",
      "Row(PersonInfo=u'21 1 00 00 0', prediction=0.0, probability=DenseVector([0.8478, 0.1522]))\n",
      "Row(PersonInfo=u'32 1 00 00 4', prediction=0.0, probability=DenseVector([0.9658, 0.0342]))\n",
      "Row(PersonInfo=u'22 3 10 00 0', prediction=0.0, probability=DenseVector([0.6825, 0.3175]))\n",
      "Row(PersonInfo=u'22 1 10 00 0', prediction=0.0, probability=DenseVector([0.8123, 0.1877]))\n",
      "Row(PersonInfo=u'19 3 00 00 0', prediction=0.0, probability=DenseVector([0.8193, 0.1807]))\n",
      "Row(PersonInfo=u'21 3 10 01 0', prediction=1.0, probability=DenseVector([0.2727, 0.7273]))\n",
      "Row(PersonInfo=u'30 3 00 00 0', prediction=0.0, probability=DenseVector([0.7861, 0.2139]))\n",
      "Row(PersonInfo=u'17 3 00 00 0', prediction=0.0, probability=DenseVector([0.6486, 0.3514]))\n",
      "Row(PersonInfo=u'23 3 00 00 2', prediction=0.0, probability=DenseVector([0.6457, 0.3543]))\n",
      "Row(PersonInfo=u'24 3 00 00 0', prediction=0.0, probability=DenseVector([0.7861, 0.2139]))\n",
      "Row(PersonInfo=u'28 1 00 00 0', prediction=0.0, probability=DenseVector([0.9398, 0.0602]))\n",
      "Row(PersonInfo=u'20 3 01 01 1', prediction=1.0, probability=DenseVector([0.298, 0.702]))\n",
      "Row(PersonInfo=u'31 3 10 00 2', prediction=0.0, probability=DenseVector([0.5644, 0.4356]))\n",
      "Row(PersonInfo=u'23 3 10 00 1', prediction=0.0, probability=DenseVector([0.5416, 0.4584]))\n",
      "Row(PersonInfo=u'18 2 00 00 0', prediction=0.0, probability=DenseVector([0.9072, 0.0928]))\n",
      "Row(PersonInfo=u'20 2 10 00 0', prediction=0.0, probability=DenseVector([0.6825, 0.3175]))\n",
      "Row(PersonInfo=u'23 1 00 00 0', prediction=0.0, probability=DenseVector([0.7482, 0.2518]))\n",
      "Row(PersonInfo=u'32 1 00 00 0', prediction=0.0, probability=DenseVector([0.9398, 0.0602]))\n",
      "Row(PersonInfo=u'23 3 00 00 0', prediction=0.0, probability=DenseVector([0.5962, 0.4038]))\n",
      "Row(PersonInfo=u'19 3 00 00 0', prediction=0.0, probability=DenseVector([0.8193, 0.1807]))\n",
      "Row(PersonInfo=u'36 1 00 00 0', prediction=0.0, probability=DenseVector([0.8168, 0.1832]))\n",
      "Row(PersonInfo=u'21 3 00 00 2', prediction=0.0, probability=DenseVector([0.7736, 0.2264]))\n",
      "Row(PersonInfo=u'19 1 10 10 0', prediction=0.0, probability=DenseVector([0.6722, 0.3278]))\n",
      "Row(PersonInfo=u'33 3 00 00 3', prediction=0.0, probability=DenseVector([0.755, 0.245]))\n",
      "Row(PersonInfo=u'20 1 10 00 1', prediction=0.0, probability=DenseVector([0.8323, 0.1677]))\n",
      "Row(PersonInfo=u'18 1 10 01 0', prediction=0.0, probability=DenseVector([0.6443, 0.3557]))\n",
      "Row(PersonInfo=u'22 1 00 00 1', prediction=0.0, probability=DenseVector([0.939, 0.061]))\n",
      "Row(PersonInfo=u'30 3 01 01 2', prediction=1.0, probability=DenseVector([0.2702, 0.7298]))\n",
      "Row(PersonInfo=u'AGE RACE SMOKEPTL HTUI FTV', prediction=1.0, probability=DenseVector([0.0754, 0.9246]))\n",
      "Row(PersonInfo=u'24 2 01 00 1', prediction=0.0, probability=DenseVector([0.7228, 0.2772]))\n",
      "Row(PersonInfo=u'16 1 10 00 0', prediction=0.0, probability=DenseVector([0.9441, 0.0559]))\n",
      "Row(PersonInfo=u'24 3 00 10 0', prediction=0.0, probability=DenseVector([0.6353, 0.3647]))\n",
      "Row(PersonInfo=u'30 1 00 00 1', prediction=0.0, probability=DenseVector([0.9258, 0.0742]))\n",
      "Row(PersonInfo=u'19 1 10 10 0', prediction=0.0, probability=DenseVector([0.6722, 0.3278]))\n",
      "Row(PersonInfo=u'24 3 01 00 0', prediction=0.0, probability=DenseVector([0.5122, 0.4878]))\n",
      "Row(PersonInfo=u'23 1 00 00 1', prediction=0.0, probability=DenseVector([0.8338, 0.1662]))\n",
      "Row(PersonInfo=u'30 1 00 00 1', prediction=0.0, probability=DenseVector([0.9258, 0.0742]))\n",
      "Row(PersonInfo=u'32 1 00 00 2', prediction=0.0, probability=DenseVector([0.9506, 0.0494]))\n",
      "Row(PersonInfo=u'28 3 00 00 1', prediction=0.0, probability=DenseVector([0.929, 0.071]))\n",
      "Row(PersonInfo=u'14 1 00 00 0', prediction=0.0, probability=DenseVector([0.6903, 0.3097]))\n",
      "Row(PersonInfo=u'25 1 00 00 2', prediction=0.0, probability=DenseVector([0.9185, 0.0815]))\n",
      "Row(PersonInfo=u'26 3 00 00 0', prediction=0.0, probability=DenseVector([0.747, 0.253]))\n",
      "Row(PersonInfo=u'32 1 10 00 0', prediction=0.0, probability=DenseVector([0.8809, 0.1191]))\n",
      "Row(PersonInfo=u'22 1 00 00 0', prediction=0.0, probability=DenseVector([0.9013, 0.0987]))\n",
      "Row(PersonInfo=u'31 1 00 00 2', prediction=0.0, probability=DenseVector([0.8462, 0.1538]))\n",
      "Row(PersonInfo=u'25 3 00 00 0', prediction=0.0, probability=DenseVector([0.8193, 0.1807]))\n",
      "Row(PersonInfo=u'16 3 00 00 1', prediction=0.0, probability=DenseVector([0.9676, 0.0324]))\n",
      "Row(PersonInfo=u'21 3 00 00 0', prediction=0.0, probability=DenseVector([0.7347, 0.2653]))\n",
      "Row(PersonInfo=u'19 1 00 00 2', prediction=0.0, probability=DenseVector([0.9185, 0.0815]))\n",
      "Row(PersonInfo=u'24 1 00 00 0', prediction=0.0, probability=DenseVector([0.8809, 0.1191]))\n",
      "Row(PersonInfo=u'28 3 11 01 0', prediction=1.0, probability=DenseVector([0.1596, 0.8404]))\n",
      "Row(PersonInfo=u'27 2 00 01 0', prediction=1.0, probability=DenseVector([0.4822, 0.5178]))\n",
      "Row(PersonInfo=u'20 3 10 01 0', prediction=1.0, probability=DenseVector([0.2945, 0.7055]))\n",
      "Row(PersonInfo=u'25 3 01 00 1', prediction=0.0, probability=DenseVector([0.6862, 0.3138]))\n",
      "Row(PersonInfo=u'18 3 00 00 0', prediction=0.0, probability=DenseVector([0.8692, 0.1308]))\n",
      "Row(PersonInfo=u'21 3 01 00 4', prediction=0.0, probability=DenseVector([0.5885, 0.4115]))\n",
      "Row(PersonInfo=u'26 3 00 00 0', prediction=0.0, probability=DenseVector([0.747, 0.253]))\n",
      "Row(PersonInfo=u'15 1 00 00 0', prediction=0.0, probability=DenseVector([0.8168, 0.1832]))\n",
      "Row(PersonInfo=u'20 2 10 00 0', prediction=0.0, probability=DenseVector([0.6825, 0.3175]))\n",
      "Row(PersonInfo=u'15 3 00 01 0', prediction=1.0, probability=DenseVector([0.3876, 0.6124]))\n",
      "Row(PersonInfo=u'30 1 11 00 0', prediction=1.0, probability=DenseVector([0.388, 0.612]))\n",
      "Row(PersonInfo=u'26 3 01 10 1', prediction=1.0, probability=DenseVector([0.403, 0.597]))\n",
      "Row(PersonInfo=u'28 1 10 00 2', prediction=0.0, probability=DenseVector([0.9013, 0.0987]))\n",
      "Row(PersonInfo=u'14 3 00 00 2', prediction=0.0, probability=DenseVector([0.5775, 0.4225]))\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test documents and print columns of interest\n",
    "prediction = model.transform(test)\n",
    "selected = prediction.select(\"PersonInfo\", \"prediction\", \"probability\")\n",
    "for row in selected.collect():\n",
    "    print row\n",
    "#for row in prediction.collect():\n",
    "#    print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|0.0       |66   |\n",
      "|1.0       |10   |\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tabulate the predicted outcome\n",
    "prediction.select(\"prediction\").groupBy(\"prediction\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|0.0  |53   |\n",
      "|1.0  |23   |\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tabulate the actual outcome\n",
    "prediction.select(\"label\").groupBy(\"label\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---+---+\n",
      "|label_prediction|0.0|1.0|\n",
      "+----------------+---+---+\n",
      "|             1.0| 16|  7|\n",
      "|             0.0| 50|  3|\n",
      "+----------------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This table shows:\n",
    "# 1. The number of low birth weight infants predicted as having low birth weight\n",
    "# 2. The number of low birth weight infants predicted as not having low birth weight\n",
    "# 3. The number of regular birth weight infants predicted as having low birth weight\n",
    "# 4. The number of regular birth weight infants predicted as not having low birth weight\n",
    "\n",
    "prediction.crosstab('label', 'prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluate_model_2\"></a>\n",
    "## Evaluate Naive Bayes Model\n",
    "\n",
    "We evaluate the model on a training set and on a test set.  The purpose is to measure the model's predictive accuracy, including the accuracy for new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Measure = 0.526315789474\n",
      "Training Accuracy = 0.763157894737\n",
      "Training Error = 0.236842105263\n",
      "Precision = 0.75\n",
      "Recall = 0.405405405405\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Naive Bayes model on a training set\n",
    "# Select (prediction, true label) and compute training error\n",
    "pred_nb=model.transform(train).select(\"prediction\", \"label\")\n",
    "eval_nb=MulticlassClassificationEvaluator (\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_nb=eval_nb.evaluate(pred_nb)\n",
    "# create RDD\n",
    "predictionAndLabels_nb=pred_nb.rdd\n",
    "metrics_nb=MulticlassMetrics(predictionAndLabels_nb)\n",
    "precision_nb=metrics_nb.precision(1.0)\n",
    "recall_nb=metrics_nb.recall(1.0)\n",
    "f1Measure_nb = metrics_nb.fMeasure(1.0, 1.0)\n",
    "print(\"F1 Measure = %s\" % f1Measure_nb)\n",
    "print (\"Training Accuracy = %s\" %accuracy_nb)\n",
    "print (\"Training Error = %s\" % (1-accuracy_nb))\n",
    "print (\"Precision = %s\" %precision_nb)\n",
    "print (\"Recall = %s\" %recall_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Measure = 0.424242424242\n",
      "Test Accuracy = 0.75\n",
      "Test Error = 0.25\n",
      "Precision = 0.7\n",
      "Recall = 0.304347826087\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Naive Bayes model on a test set\n",
    "# Select (prediction, true label) and compute test error\n",
    "pred_nb=model.transform(test).select(\"prediction\", \"label\")\n",
    "eval_nb=MulticlassClassificationEvaluator (\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_nb=eval_nb.evaluate(pred_nb)\n",
    "# create RDD\n",
    "predictionAndLabels_nb=pred_nb.rdd\n",
    "metrics_nb=MulticlassMetrics(predictionAndLabels_nb)\n",
    "precision_nb=metrics_nb.precision(1.0)\n",
    "recall_nb=metrics_nb.recall(1.0)\n",
    "f1Measure_nb = metrics_nb.fMeasure(1.0, 1.0)\n",
    "print(\"F1 Measure = %s\" % f1Measure_nb)\n",
    "print (\"Test Accuracy = %s\" %accuracy_nb)\n",
    "print (\"Test Error = %s\" % (1-accuracy_nb))\n",
    "print (\"Precision = %s\" %precision_nb)\n",
    "print (\"Recall = %s\" %recall_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under PR = 0.607437070938\n",
      "Area under ROC = 0.623872026251\n"
     ]
    }
   ],
   "source": [
    "bin_nb=BinaryClassificationMetrics(predictionAndLabels_nb)\n",
    "\n",
    "# Area under precision-recall curve\n",
    "print(\"Area under PR = %s\" % bin_nb.areaUnderPR)\n",
    "# Area under precision-recall curve\n",
    "print(\"Area under ROC = %s\" % bin_nb.areaUnderROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"build_model_3\"></a>\n",
    "## Build Decision Tree Model\n",
    "\n",
    "We use the Pipeline of SparkML to build the Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Decision Tree using Pipeline of SparkML\n",
    "tokenizer = Tokenizer(inputCol=\"PersonInfo\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\", numFeatures=32)\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Decision Tree Model\n",
    "# the stages are executed in order\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test_data_3\"></a>\n",
    "## Decision Tree Predictions for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(PersonInfo=u'18 1 10 00 0', prediction=0.0, probability=DenseVector([0.7297, 0.2703]))\n",
      "Row(PersonInfo=u'15 2 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'25 1 10 00 3', prediction=1.0, probability=DenseVector([0.4667, 0.5333]))\n",
      "Row(PersonInfo=u'36 1 00 00 1', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'25 3 00 01 2', prediction=1.0, probability=DenseVector([0.4667, 0.5333]))\n",
      "Row(PersonInfo=u'17 2 00 00 1', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'17 2 00 00 1', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'24 1 11 00 1', prediction=1.0, probability=DenseVector([0.0, 1.0]))\n",
      "Row(PersonInfo=u'25 2 00 00 0', prediction=0.0, probability=DenseVector([1.0, 0.0]))\n",
      "Row(PersonInfo=u'27 1 10 00 0', prediction=0.0, probability=DenseVector([0.7297, 0.2703]))\n",
      "Row(PersonInfo=u'31 1 10 00 2', prediction=0.0, probability=DenseVector([0.7297, 0.2703]))\n",
      "Row(PersonInfo=u'19 1 00 00 2', prediction=0.0, probability=DenseVector([1.0, 0.0]))\n",
      "Row(PersonInfo=u'21 1 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'32 1 00 00 4', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'22 3 10 00 0', prediction=1.0, probability=DenseVector([0.4667, 0.5333]))\n",
      "Row(PersonInfo=u'22 1 10 00 0', prediction=0.0, probability=DenseVector([0.7297, 0.2703]))\n",
      "Row(PersonInfo=u'19 3 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'21 3 10 01 0', prediction=1.0, probability=DenseVector([0.4667, 0.5333]))\n",
      "Row(PersonInfo=u'30 3 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'17 3 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'23 3 00 00 2', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'24 3 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'28 1 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'20 3 01 01 1', prediction=1.0, probability=DenseVector([0.4667, 0.5333]))\n",
      "Row(PersonInfo=u'31 3 10 00 2', prediction=1.0, probability=DenseVector([0.4667, 0.5333]))\n",
      "Row(PersonInfo=u'23 3 10 00 1', prediction=1.0, probability=DenseVector([0.0, 1.0]))\n",
      "Row(PersonInfo=u'18 2 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'20 2 10 00 0', prediction=1.0, probability=DenseVector([0.4667, 0.5333]))\n",
      "Row(PersonInfo=u'23 1 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'32 1 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'23 3 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'19 3 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'36 1 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'21 3 00 00 2', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'19 1 10 10 0', prediction=1.0, probability=DenseVector([0.0, 1.0]))\n",
      "Row(PersonInfo=u'33 3 00 00 3', prediction=0.0, probability=DenseVector([0.75, 0.25]))\n",
      "Row(PersonInfo=u'20 1 10 00 1', prediction=1.0, probability=DenseVector([0.4667, 0.5333]))\n",
      "Row(PersonInfo=u'18 1 10 01 0', prediction=0.0, probability=DenseVector([0.7297, 0.2703]))\n",
      "Row(PersonInfo=u'22 1 00 00 1', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'30 3 01 01 2', prediction=1.0, probability=DenseVector([0.4667, 0.5333]))\n",
      "Row(PersonInfo=u'AGE RACE SMOKEPTL HTUI FTV', prediction=0.0, probability=DenseVector([0.7297, 0.2703]))\n",
      "Row(PersonInfo=u'24 2 01 00 1', prediction=0.0, probability=DenseVector([0.7297, 0.2703]))\n",
      "Row(PersonInfo=u'16 1 10 00 0', prediction=0.0, probability=DenseVector([0.7297, 0.2703]))\n",
      "Row(PersonInfo=u'24 3 00 10 0', prediction=1.0, probability=DenseVector([0.0, 1.0]))\n",
      "Row(PersonInfo=u'30 1 00 00 1', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'19 1 10 10 0', prediction=1.0, probability=DenseVector([0.0, 1.0]))\n",
      "Row(PersonInfo=u'24 3 01 00 0', prediction=1.0, probability=DenseVector([0.4667, 0.5333]))\n",
      "Row(PersonInfo=u'23 1 00 00 1', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'30 1 00 00 1', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'32 1 00 00 2', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'28 3 00 00 1', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'14 1 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'25 1 00 00 2', prediction=0.0, probability=DenseVector([1.0, 0.0]))\n",
      "Row(PersonInfo=u'26 3 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'32 1 10 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'22 1 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'31 1 00 00 2', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'25 3 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'16 3 00 00 1', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'21 3 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'19 1 00 00 2', prediction=0.0, probability=DenseVector([1.0, 0.0]))\n",
      "Row(PersonInfo=u'24 1 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'28 3 11 01 0', prediction=1.0, probability=DenseVector([0.0, 1.0]))\n",
      "Row(PersonInfo=u'27 2 00 01 0', prediction=0.0, probability=DenseVector([0.7297, 0.2703]))\n",
      "Row(PersonInfo=u'20 3 10 01 0', prediction=1.0, probability=DenseVector([0.4667, 0.5333]))\n",
      "Row(PersonInfo=u'25 3 01 00 1', prediction=1.0, probability=DenseVector([0.4667, 0.5333]))\n",
      "Row(PersonInfo=u'18 3 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'21 3 01 00 4', prediction=1.0, probability=DenseVector([0.4667, 0.5333]))\n",
      "Row(PersonInfo=u'26 3 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'15 1 00 00 0', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'20 2 10 00 0', prediction=1.0, probability=DenseVector([0.4667, 0.5333]))\n",
      "Row(PersonInfo=u'15 3 00 01 0', prediction=1.0, probability=DenseVector([0.4667, 0.5333]))\n",
      "Row(PersonInfo=u'30 1 11 00 0', prediction=1.0, probability=DenseVector([0.0, 1.0]))\n",
      "Row(PersonInfo=u'26 3 01 10 1', prediction=1.0, probability=DenseVector([0.4667, 0.5333]))\n",
      "Row(PersonInfo=u'28 1 10 00 2', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n",
      "Row(PersonInfo=u'14 3 00 00 2', prediction=0.0, probability=DenseVector([0.9744, 0.0256]))\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test documents and print columns of interest\n",
    "prediction = model.transform(test)\n",
    "selected = prediction.select(\"PersonInfo\", \"prediction\", \"probability\")\n",
    "for row in selected.collect():\n",
    "    print row\n",
    "#for row in prediction.collect():\n",
    "#    print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|0.0       |53   |\n",
      "|1.0       |23   |\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tabulate the predicted outcome\n",
    "prediction.select(\"prediction\").groupBy(\"prediction\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|0.0  |53   |\n",
      "|1.0  |23   |\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tabulate the actual outcome\n",
    "prediction.select(\"label\").groupBy(\"label\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---+---+\n",
      "|label_prediction|0.0|1.0|\n",
      "+----------------+---+---+\n",
      "|             1.0| 14|  9|\n",
      "|             0.0| 39| 14|\n",
      "+----------------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This table shows:\n",
    "# 1. The number of low birth weight infants predicted as having low birth weight\n",
    "# 2. The number of low birth weight infants predicted as not having low birth weight\n",
    "# 3. The number of regular birth weight infants predicted as having low birth weight\n",
    "# 4. The number of regular birth weight infants predicted as not having low birth weight\n",
    "\n",
    "prediction.crosstab('label', 'prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluate_model_3\"></a>\n",
    "## Evaluate Decision Tree Model\n",
    "\n",
    "We evaluate the model on a training set and on a test set.  The purpose is to measure the model's predictive accuracy, including the accuracy for new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Measure = 0.724637681159\n",
      "Training Accuracy = 0.833333333333\n",
      "Training Error = 0.166666666667\n",
      "Precision = 0.78125\n",
      "Recall = 0.675675675676\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Decision Tree model on a training set\n",
    "# Select (prediction, true label) and compute training error\n",
    "pred_nb=model.transform(train).select(\"prediction\", \"label\")\n",
    "eval_nb=MulticlassClassificationEvaluator (\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_nb=eval_nb.evaluate(pred_nb)\n",
    "# create RDD\n",
    "predictionAndLabels_nb=pred_nb.rdd\n",
    "metrics_nb=MulticlassMetrics(predictionAndLabels_nb)\n",
    "precision_nb=metrics_nb.precision(1.0)\n",
    "recall_nb=metrics_nb.recall(1.0)\n",
    "f1Measure_nb = metrics_nb.fMeasure(1.0, 1.0)\n",
    "print(\"F1 Measure = %s\" % f1Measure_nb)\n",
    "print (\"Training Accuracy = %s\" %accuracy_nb)\n",
    "print (\"Training Error = %s\" % (1-accuracy_nb))\n",
    "print (\"Precision = %s\" %precision_nb)\n",
    "print (\"Recall = %s\" %recall_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Measure = 0.391304347826\n",
      "Test Accuracy = 0.631578947368\n",
      "Test Error = 0.368421052632\n",
      "Precision = 0.391304347826\n",
      "Recall = 0.391304347826\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Decision Tree model on a test set\n",
    "# Select (prediction, true label) and compute test error\n",
    "pred_nb=model.transform(test).select(\"prediction\", \"label\")\n",
    "eval_nb=MulticlassClassificationEvaluator (\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_nb=eval_nb.evaluate(pred_nb)\n",
    "# create RDD\n",
    "predictionAndLabels_nb=pred_nb.rdd\n",
    "metrics_nb=MulticlassMetrics(predictionAndLabels_nb)\n",
    "precision_nb=metrics_nb.precision(1.0)\n",
    "recall_nb=metrics_nb.recall(1.0)\n",
    "f1Measure_nb = metrics_nb.fMeasure(1.0, 1.0)\n",
    "print(\"F1 Measure = %s\" % f1Measure_nb)\n",
    "print (\"Test Accuracy = %s\" %accuracy_nb)\n",
    "print (\"Test Error = %s\" % (1-accuracy_nb))\n",
    "print (\"Precision = %s\" %precision_nb)\n",
    "print (\"Recall = %s\" %recall_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under PR = 0.483409610984\n",
      "Area under ROC = 0.563576702215\n"
     ]
    }
   ],
   "source": [
    "bin_nb=BinaryClassificationMetrics(predictionAndLabels_nb)\n",
    "\n",
    "# Area under precision-recall curve\n",
    "print(\"Area under PR = %s\" % bin_nb.areaUnderPR)\n",
    "# Area under precision-recall curve\n",
    "print(\"Area under ROC = %s\" % bin_nb.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.1",
   "language": "python",
   "name": "python2-spark21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "name": "machineLearningHAVCBluemix.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
