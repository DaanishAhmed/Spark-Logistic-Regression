{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Survival of the Titanic Passengers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Source: [https://ww2.amstat.org/publications/jse/v3n3/datasets.dawson.html](https://ww2.amstat.org/publications/jse/v3n3/datasets.dawson.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Load Libraries](#load_libraries)\n",
    "- [Access data](#access_data)\n",
    "- [Split Data into Training and Test set](#training_test)\n",
    "- [Build Logistic Regression Model](#build_model)\n",
    "- [Predict for Test data](#test_data)\n",
    "- [Evaluate the Model](#evaluate_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load_libraries\"></a>\n",
    "## Load Libraries\n",
    "\n",
    "The Spark and Python libraries that you need are preinstalled in the notebook environment and only need to be loaded.\n",
    "\n",
    "Run the following cell to load the libraries you will work with in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark Machine Learning Library\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.sql import Row, SQLContext\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from numpy import array\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# Library for confusion matrix, precision, test error\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "# Library For Area under ROC curve and Area under precision-recall curve\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "# Assign resources to the application\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data will be loaded into an array.\n",
    "# This is the summary of the data structure, including the column position and name.\n",
    "# The first filed starts from position 0. \n",
    "\n",
    "# 0 Name    -  Passenger first and last name.\n",
    "# 1 PClass  -  Passenger class (1st, 2nd, or 3rd)\n",
    "# 2 Age\n",
    "# 3 Sex\n",
    "# 4 Survived -  1 if the passenger survived;  0 if the passenger did not survive\n",
    "# 5 PersonID\n",
    "\n",
    "# Label is a target variable. PersonInfo is a list of independent variables besides unique identifier\n",
    "\n",
    "LabeledDocument = Row(\"PersonID\", \"PersonInfo\", \"label\")\n",
    "\n",
    "# Define a function that parses the raw CSV file and returns an object of type LabeledDocument\n",
    "\n",
    "def parseDocument(line):\n",
    "    values = [str(x) for x in line.split(',')] \n",
    "    if (values[4]>'0'):\n",
    "      Survived = 1.0\n",
    "    else:\n",
    "      Survived = 0.0\n",
    "        \n",
    "    textValue = str(values[1]) + \" \" + str(values[2])+\" \" + str(values[3])\n",
    "    return LabeledDocument(values[5], textValue, Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"access_data\"></a>\n",
    "## Access Data\n",
    "Before you can access data in the data file in the Object Storage, you must setup the Spark configuration with your Object Storage credentials. \n",
    "\n",
    "To do this, click on the cell below and select the **Insert to code > Insert Spark Session DataFrame** function from the Files tab below the data file you want to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">The following code contains the credentials for a file in your IBM Cloud Object Storage. Delete the code starting from `from pyspark.sql import SparkSession` line before you run the cell.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object Storage Credentials\n",
    "import ibmos2spark\n",
    "\n",
    "# @hidden_cell\n",
    "credentials = {\n",
    "    'endpoint': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n",
    "    'api_key': 'lue6np0RwcvhARfJIQNtvVTUt3I45m5qk9UHM6LFTc3B',\n",
    "    'service_id': 'iam-ServiceId-3ac1bdb0-c8a1-4ae8-abe0-2dd53ae4c6e9',\n",
    "    'iam_service_endpoint': 'https://iam.ng.bluemix.net/oidc/token'}\n",
    "\n",
    "configuration_name = 'os_9d550c7f6655453f915511631f5b077f_configs'\n",
    "cos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the data into a `Spark RDD` and output the number of rows and first 5 rows.\n",
    "Each project you create has a bucket in your object storage. You can get the bucket name from the project Settings page. Change the string `BUCKET` to the bucket name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in the data set: 757\n",
      "The first 5 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'Name,PClass,Age,Sex,Survived,PersonID',\n",
       " u'Allen Miss Elisabeth Walton,1st,29,female,1,1',\n",
       " u'Allison Miss Helen Loraine,1st,2,female,0,2',\n",
       " u'Allison Mr Hudson Joshua Creighton,1st,30,male,0,3',\n",
       " u'Allison Mrs Hudson JC (Bessie Waldo Daniels),1st,25,female,0,4']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.textFile(cos.url('Titanic.csv', 'assignment331c5c83422a7434ab113135bf62f5fb0'))\n",
    "print \"Total records in the data set:\", data.count()\n",
    "print \"The first 5 rows\"\n",
    "data.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crate DataFrame from RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 756\n",
      "First 5 records: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(PersonID=u'1', PersonInfo=u'1st 29 female', label=1.0),\n",
       " Row(PersonID=u'2', PersonInfo=u'1st 2 female', label=0.0),\n",
       " Row(PersonID=u'3', PersonInfo=u'1st 30 male', label=0.0),\n",
       " Row(PersonID=u'4', PersonInfo=u'1st 25 female', label=0.0),\n",
       " Row(PersonID=u'5', PersonInfo=u'1st 0.92 male', label=1.0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data into a dataframe, parse it using the function above\n",
    "documents = data.filter(lambda s: \"Name\" not in s).map(parseDocument)\n",
    "TitanicData = documents.toDF() # ToDataFrame\n",
    "print \"Number of records: \" + str(TitanicData.count())\n",
    "print \"First 5 records: \"\n",
    "TitanicData.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"training_test\"></a>\n",
    "## Split Data into Training and Test set\n",
    "\n",
    "We divide the data into training and test set.  The training set is used to build the model to be used on future data, and the test set is used to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in the training set: 624\n",
      "Number of records in the test set: 132\n",
      "First 20 records in the training set: \n",
      "+--------+-------------+-----+\n",
      "|PersonID|   PersonInfo|label|\n",
      "+--------+-------------+-----+\n",
      "|       1|1st 29 female|  1.0|\n",
      "|      10|  1st 71 male|  0.0|\n",
      "|     100|  1st 46 male|  0.0|\n",
      "|     101|  1st 25 male|  1.0|\n",
      "|     102|1st 21 female|  1.0|\n",
      "|     104|1st 49 female|  1.0|\n",
      "|     106|1st 36 female|  1.0|\n",
      "|     107|  1st 55 male|  0.0|\n",
      "|     108|1st 52 female|  1.0|\n",
      "|     109|1st 24 female|  1.0|\n",
      "|      11|  1st 47 male|  0.0|\n",
      "|     110|1st 16 female|  1.0|\n",
      "|     112|1st 51 female|  1.0|\n",
      "|     113|  1st 42 male|  0.0|\n",
      "|     114|1st 35 female|  1.0|\n",
      "|     115|  1st 35 male|  1.0|\n",
      "|     116|  1st 38 male|  1.0|\n",
      "|     117|1st 35 female|  1.0|\n",
      "|     118|1st 50 female|  0.0|\n",
      "|     119|  1st 49 male|  1.0|\n",
      "+--------+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Divide the data into training and test set\n",
    "(train, test) = TitanicData.randomSplit([0.8, 0.2])\n",
    "print \"Number of records in the training set: \" + str(train.count())\n",
    "print \"Number of records in the test set: \" + str(test.count())\n",
    "# Output first 20 records in the training set\n",
    "print \"First 20 records in the training set: \"\n",
    "train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"build_model\"></a>\n",
    "## Build Logistic Regression Model\n",
    "\n",
    "We use the Pipeline of SparkML to build the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Logistic Regression using Pipeline of SparkML\n",
    "tokenizer = Tokenizer(inputCol=\"PersonInfo\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(262144, {1251: -3.0553, 4106: -3.18, 8612: -1.0636, 18659: 0.1234, 23689: -0.1167, 24537: -0.236, 31351: 0.1305, 32672: -0.322, 37812: 0.359, 43733: -1.3179, 56811: 0.3897, 60486: 1.0426, 63384: -1.0556, 64358: 0.2618, 68516: -1.0626, 69821: -0.3466, 78326: -1.5195, 82742: 3.5571, 83214: 0.0855, 83863: -0.3072, 89074: 4.8292, 89689: 1.5756, 98627: -0.9334, 98962: 3.7439, 102033: -1.3534, 104268: -2.9561, 109681: -1.3979, 110466: -0.0096, 114415: 0.085, 122111: 1.9757, 122295: 1.3757, 127663: -0.7429, 128319: 0.4579, 130010: 0.4102, 130972: -1.5104, 134360: -0.9008, 139093: 1.5487, 146429: 1.1346, 147946: -0.2807, 153779: -0.8924, 155743: 3.2298, 162286: 0.047, 167741: -3.4939, 173170: 0.3013, 175329: 0.4599, 177493: 0.8597, 177523: -1.2967, 178347: -0.574, 180089: 4.5844, 186753: -1.7762, 187043: 0.0149, 191455: -0.2434, 197774: 4.5844, 199158: -3.1773, 201434: 1.4816, 206255: 1.3514, 207020: 0.1765, 212053: -0.1292, 213217: 0.5011, 219381: 0.2654, 230679: -0.6161, 232155: -1.2509, 233878: 1.7085, 236232: 4.5973, 241667: -0.7597, 241900: -2.9561, 246049: -3.1773, 250051: 0.1157, 250100: -3.1773, 250733: -0.4389, 250802: 0.398, 252401: 0.0002, 252551: -1.5116, 257339: -0.0872, 258253: -0.7048, 259362: 2.3979, 259523: -3.4926, 261374: 1.6615})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up Logistic Regression Model\n",
    "# the stages are executed in order\n",
    "model = pipeline.fit(train)\n",
    "#[stage.coefficients for stage in model.stages if hasattr(stage, \"coefficients\")]\n",
    "# model.stages[2].intercept\n",
    "model.stages[2].coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test_data\"></a>\n",
    "## Predict for Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(PersonInfo=u'1st 48 male', prediction=0.0, probability=DenseVector([0.581, 0.419]))\n",
      "Row(PersonInfo=u'1st 45 male', prediction=0.0, probability=DenseVector([0.5084, 0.4916]))\n",
      "Row(PersonInfo=u'1st 44 female', prediction=1.0, probability=DenseVector([0.1559, 0.8441]))\n",
      "Row(PersonInfo=u'1st 41 male', prediction=0.0, probability=DenseVector([0.7217, 0.2783]))\n",
      "Row(PersonInfo=u'1st 30 male', prediction=0.0, probability=DenseVector([0.7583, 0.2417]))\n",
      "Row(PersonInfo=u'1st 64 male', prediction=0.0, probability=DenseVector([0.8793, 0.1207]))\n",
      "Row(PersonInfo=u'1st 46 male', prediction=0.0, probability=DenseVector([0.9632, 0.0368]))\n",
      "Row(PersonInfo=u'1st 33 female', prediction=1.0, probability=DenseVector([0.0627, 0.9373]))\n",
      "Row(PersonInfo=u'1st 13 male', prediction=0.0, probability=DenseVector([0.8483, 0.1517]))\n",
      "Row(PersonInfo=u'1st 50 male', prediction=0.0, probability=DenseVector([0.7251, 0.2749]))\n",
      "Row(PersonInfo=u'1st 24 male', prediction=0.0, probability=DenseVector([0.5486, 0.4514]))\n",
      "Row(PersonInfo=u'1st 45 male', prediction=0.0, probability=DenseVector([0.5084, 0.4916]))\n",
      "Row(PersonInfo=u'1st 40 female', prediction=1.0, probability=DenseVector([0.1176, 0.8824]))\n",
      "Row(PersonInfo=u'1st 25 male', prediction=1.0, probability=DenseVector([0.343, 0.657]))\n",
      "Row(PersonInfo=u'1st 52 female', prediction=1.0, probability=DenseVector([0.0698, 0.9302]))\n",
      "Row(PersonInfo=u'1st 62 female', prediction=0.0, probability=DenseVector([0.6429, 0.3571]))\n",
      "Row(PersonInfo=u'1st 46 female', prediction=0.0, probability=DenseVector([0.6144, 0.3856]))\n",
      "Row(PersonInfo=u'1st 49 male', prediction=1.0, probability=DenseVector([0.3031, 0.6969]))\n",
      "Row(PersonInfo=u'1st 46 male', prediction=0.0, probability=DenseVector([0.9632, 0.0368]))\n",
      "Row(PersonInfo=u'1st 31 male', prediction=0.0, probability=DenseVector([0.6203, 0.3797]))\n",
      "Row(PersonInfo=u'1st 60 female', prediction=1.0, probability=DenseVector([0.0526, 0.9474]))\n",
      "Row(PersonInfo=u'1st 55 female', prediction=1.0, probability=DenseVector([0.2251, 0.7749]))\n",
      "Row(PersonInfo=u'1st 45 female', prediction=1.0, probability=DenseVector([0.0592, 0.9408]))\n",
      "Row(PersonInfo=u'1st 31 female', prediction=1.0, probability=DenseVector([0.0904, 0.9096]))\n",
      "Row(PersonInfo=u'2nd 30 male', prediction=0.0, probability=DenseVector([0.9222, 0.0778]))\n",
      "Row(PersonInfo=u'2nd 28 male', prediction=0.0, probability=DenseVector([0.8682, 0.1318]))\n",
      "Row(PersonInfo=u'2nd 32 male', prediction=0.0, probability=DenseVector([0.5997, 0.4003]))\n",
      "Row(PersonInfo=u'2nd 19 female', prediction=1.0, probability=DenseVector([0.0568, 0.9432]))\n",
      "Row(PersonInfo=u'2nd 23 male', prediction=0.0, probability=DenseVector([0.8035, 0.1965]))\n",
      "Row(PersonInfo=u'2nd 19 male', prediction=1.0, probability=DenseVector([0.4975, 0.5025]))\n",
      "Row(PersonInfo=u'2nd 54 male', prediction=0.0, probability=DenseVector([0.8106, 0.1894]))\n",
      "Row(PersonInfo=u'2nd 30 male', prediction=0.0, probability=DenseVector([0.9222, 0.0778]))\n",
      "Row(PersonInfo=u'1st 45 female', prediction=1.0, probability=DenseVector([0.0592, 0.9408]))\n",
      "Row(PersonInfo=u'2nd 22 female', prediction=1.0, probability=DenseVector([0.1785, 0.8215]))\n",
      "Row(PersonInfo=u'2nd 32 female', prediction=1.0, probability=DenseVector([0.0835, 0.9165]))\n",
      "Row(PersonInfo=u'2nd 34 female', prediction=1.0, probability=DenseVector([0.1652, 0.8348]))\n",
      "Row(PersonInfo=u'2nd 8 male', prediction=1.0, probability=DenseVector([0.0993, 0.9007]))\n",
      "Row(PersonInfo=u'2nd 19 male', prediction=1.0, probability=DenseVector([0.4975, 0.5025]))\n",
      "Row(PersonInfo=u'2nd 38 female', prediction=1.0, probability=DenseVector([0.161, 0.839]))\n",
      "Row(PersonInfo=u'2nd 35 male', prediction=0.0, probability=DenseVector([0.7384, 0.2616]))\n",
      "Row(PersonInfo=u'2nd 24 female', prediction=1.0, probability=DenseVector([0.2183, 0.7817]))\n",
      "Row(PersonInfo=u'2nd 45 male', prediction=0.0, probability=DenseVector([0.7961, 0.2039]))\n",
      "Row(PersonInfo=u'2nd 24 male', prediction=0.0, probability=DenseVector([0.8211, 0.1789]))\n",
      "Row(PersonInfo=u'2nd 30 male', prediction=0.0, probability=DenseVector([0.9222, 0.0778]))\n",
      "Row(PersonInfo=u'2nd 45 female', prediction=1.0, probability=DenseVector([0.1919, 0.8081]))\n",
      "Row(PersonInfo=u'2nd 7 female', prediction=1.0, probability=DenseVector([0.2208, 0.7792]))\n",
      "Row(PersonInfo=u'2nd 24 female', prediction=1.0, probability=DenseVector([0.2183, 0.7817]))\n",
      "Row(PersonInfo=u'2nd 21 male', prediction=0.0, probability=DenseVector([0.855, 0.145]))\n",
      "Row(PersonInfo=u'1st 60 female', prediction=1.0, probability=DenseVector([0.0526, 0.9474]))\n",
      "Row(PersonInfo=u'2nd 52 male', prediction=0.0, probability=DenseVector([0.8232, 0.1768]))\n",
      "Row(PersonInfo=u'2nd 41 male', prediction=0.0, probability=DenseVector([0.9073, 0.0927]))\n",
      "Row(PersonInfo=u'2nd 33 male', prediction=0.0, probability=DenseVector([0.8058, 0.1942]))\n",
      "Row(PersonInfo=u'2nd 31 male', prediction=0.0, probability=DenseVector([0.8605, 0.1395]))\n",
      "Row(PersonInfo=u'2nd 26 male', prediction=0.0, probability=DenseVector([0.7466, 0.2534]))\n",
      "Row(PersonInfo=u'2nd 48 male', prediction=0.0, probability=DenseVector([0.8396, 0.1604]))\n",
      "Row(PersonInfo=u'2nd 57 female', prediction=0.0, probability=DenseVector([0.8449, 0.1551]))\n",
      "Row(PersonInfo=u'2nd 2 male', prediction=0.0, probability=DenseVector([0.8413, 0.1587]))\n",
      "Row(PersonInfo=u'2nd 27 male', prediction=0.0, probability=DenseVector([0.8247, 0.1753]))\n",
      "Row(PersonInfo=u'2nd 19 female', prediction=1.0, probability=DenseVector([0.0568, 0.9432]))\n",
      "Row(PersonInfo=u'1st 25 female', prediction=1.0, probability=DenseVector([0.0308, 0.9692]))\n",
      "Row(PersonInfo=u'1st 70 male', prediction=0.0, probability=DenseVector([0.5523, 0.4477]))\n",
      "Row(PersonInfo=u'1st 47 male', prediction=0.0, probability=DenseVector([0.8493, 0.1507]))\n",
      "Row(PersonInfo=u'1st 4 male', prediction=1.0, probability=DenseVector([0.1827, 0.8173]))\n",
      "Row(PersonInfo=u'1st 50 male', prediction=0.0, probability=DenseVector([0.7251, 0.2749]))\n",
      "Row(PersonInfo=u'1st 63 female', prediction=1.0, probability=DenseVector([0.2154, 0.7846]))\n",
      "Row(PersonInfo=u'1st 30 male', prediction=0.0, probability=DenseVector([0.7583, 0.2417]))\n",
      "Row(PersonInfo=u'1st 28 female', prediction=1.0, probability=DenseVector([0.096, 0.904]))\n",
      "Row(PersonInfo=u'1st 22 female', prediction=1.0, probability=DenseVector([0.0544, 0.9456]))\n",
      "Row(PersonInfo=u'1st 45 female', prediction=1.0, probability=DenseVector([0.0592, 0.9408]))\n",
      "Row(PersonInfo=u'1st 38 male', prediction=1.0, probability=DenseVector([0.4552, 0.5448]))\n",
      "Row(PersonInfo=u'1st 45 female', prediction=1.0, probability=DenseVector([0.0592, 0.9408]))\n",
      "Row(PersonInfo=u'2nd 45 male', prediction=0.0, probability=DenseVector([0.7961, 0.2039]))\n",
      "Row(PersonInfo=u'2nd 13 female', prediction=0.0, probability=DenseVector([0.5624, 0.4376]))\n",
      "Row(PersonInfo=u'2nd 32 male', prediction=0.0, probability=DenseVector([0.5997, 0.4003]))\n",
      "Row(PersonInfo=u'2nd 32 male', prediction=0.0, probability=DenseVector([0.5997, 0.4003]))\n",
      "Row(PersonInfo=u'2nd 19 male', prediction=1.0, probability=DenseVector([0.4975, 0.5025]))\n",
      "Row(PersonInfo=u'2nd 34 male', prediction=0.0, probability=DenseVector([0.7649, 0.2351]))\n",
      "Row(PersonInfo=u'2nd 50 female', prediction=1.0, probability=DenseVector([0.3773, 0.6227]))\n",
      "Row(PersonInfo=u'2nd 22 male', prediction=0.0, probability=DenseVector([0.7813, 0.2187]))\n",
      "Row(PersonInfo=u'2nd 12 female', prediction=1.0, probability=DenseVector([0.0251, 0.9749]))\n",
      "Row(PersonInfo=u'3rd 16 male', prediction=0.0, probability=DenseVector([0.8992, 0.1008]))\n",
      "Row(PersonInfo=u'3rd 18 female', prediction=0.0, probability=DenseVector([0.5714, 0.4286]))\n",
      "Row(PersonInfo=u'3rd 0.83 male', prediction=1.0, probability=DenseVector([0.1261, 0.8739]))\n",
      "Row(PersonInfo=u'3rd 20 male', prediction=0.0, probability=DenseVector([0.9047, 0.0953]))\n",
      "Row(PersonInfo=u'3rd 25 male', prediction=0.0, probability=DenseVector([0.8567, 0.1433]))\n",
      "Row(PersonInfo=u'3rd 32 male', prediction=0.0, probability=DenseVector([0.8196, 0.1804]))\n",
      "Row(PersonInfo=u'3rd 18 female', prediction=0.0, probability=DenseVector([0.5714, 0.4286]))\n",
      "Row(PersonInfo=u'3rd 35 male', prediction=0.0, probability=DenseVector([0.8954, 0.1046]))\n",
      "Row(PersonInfo=u'3rd 27 male', prediction=0.0, probability=DenseVector([0.9345, 0.0655]))\n",
      "Row(PersonInfo=u'3rd 20 male', prediction=0.0, probability=DenseVector([0.9047, 0.0953]))\n",
      "Row(PersonInfo=u'3rd 40 male', prediction=0.0, probability=DenseVector([0.9617, 0.0383]))\n",
      "Row(PersonInfo=u'3rd 15 female', prediction=1.0, probability=DenseVector([0.182, 0.818]))\n",
      "Row(PersonInfo=u'3rd 22 male', prediction=0.0, probability=DenseVector([0.9155, 0.0845]))\n",
      "Row(PersonInfo=u'3rd 21 male', prediction=0.0, probability=DenseVector([0.9471, 0.0529]))\n",
      "Row(PersonInfo=u'3rd 20 female', prediction=1.0, probability=DenseVector([0.366, 0.634]))\n",
      "Row(PersonInfo=u'3rd 29 male', prediction=0.0, probability=DenseVector([0.9284, 0.0716]))\n",
      "Row(PersonInfo=u'3rd 19 male', prediction=0.0, probability=DenseVector([0.7502, 0.2498]))\n",
      "Row(PersonInfo=u'3rd 18 male', prediction=0.0, probability=DenseVector([0.9564, 0.0436]))\n",
      "Row(PersonInfo=u'3rd 38 male', prediction=0.0, probability=DenseVector([0.9054, 0.0946]))\n",
      "Row(PersonInfo=u'3rd 17 male', prediction=0.0, probability=DenseVector([0.9158, 0.0842]))\n",
      "Row(PersonInfo=u'3rd 28 male', prediction=0.0, probability=DenseVector([0.9523, 0.0477]))\n",
      "Row(PersonInfo=u'3rd 35 male', prediction=0.0, probability=DenseVector([0.8954, 0.1046]))\n",
      "Row(PersonInfo=u'3rd 30 male', prediction=0.0, probability=DenseVector([0.9729, 0.0271]))\n",
      "Row(PersonInfo=u'3rd 9 male', prediction=0.0, probability=DenseVector([0.9718, 0.0282]))\n",
      "Row(PersonInfo=u'3rd 19 male', prediction=0.0, probability=DenseVector([0.7502, 0.2498]))\n",
      "Row(PersonInfo=u'3rd 30 female', prediction=0.0, probability=DenseVector([0.6861, 0.3139]))\n",
      "Row(PersonInfo=u'3rd 19 female', prediction=1.0, probability=DenseVector([0.1545, 0.8455]))\n",
      "Row(PersonInfo=u'3rd 65 male', prediction=0.0, probability=DenseVector([0.9971, 0.0029]))\n",
      "Row(PersonInfo=u'3rd 32 male', prediction=0.0, probability=DenseVector([0.8196, 0.1804]))\n",
      "Row(PersonInfo=u'3rd 24 male', prediction=0.0, probability=DenseVector([0.933, 0.067]))\n",
      "Row(PersonInfo=u'3rd 23 male', prediction=0.0, probability=DenseVector([0.9254, 0.0746]))\n",
      "Row(PersonInfo=u'3rd 45 male', prediction=0.0, probability=DenseVector([0.9221, 0.0779]))\n",
      "Row(PersonInfo=u'3rd 25 male', prediction=0.0, probability=DenseVector([0.8567, 0.1433]))\n",
      "Row(PersonInfo=u'3rd 41 male', prediction=0.0, probability=DenseVector([0.9674, 0.0326]))\n",
      "Row(PersonInfo=u'3rd 28 male', prediction=0.0, probability=DenseVector([0.9523, 0.0477]))\n",
      "Row(PersonInfo=u'3rd 41 male', prediction=0.0, probability=DenseVector([0.9674, 0.0326]))\n",
      "Row(PersonInfo=u'3rd 21 male', prediction=0.0, probability=DenseVector([0.9471, 0.0529]))\n",
      "Row(PersonInfo=u'3rd 27 female', prediction=1.0, probability=DenseVector([0.4646, 0.5354]))\n",
      "Row(PersonInfo=u'3rd 25 female', prediction=1.0, probability=DenseVector([0.2668, 0.7332]))\n",
      "Row(PersonInfo=u'3rd 32 male', prediction=0.0, probability=DenseVector([0.8196, 0.1804]))\n",
      "Row(PersonInfo=u'3rd 4 male', prediction=0.0, probability=DenseVector([0.7191, 0.2809]))\n",
      "Row(PersonInfo=u'3rd 32 male', prediction=0.0, probability=DenseVector([0.8196, 0.1804]))\n",
      "Row(PersonInfo=u'3rd 21 female', prediction=0.0, probability=DenseVector([0.5212, 0.4788]))\n",
      "Row(PersonInfo=u'3rd 21 male', prediction=0.0, probability=DenseVector([0.9471, 0.0529]))\n",
      "Row(PersonInfo=u'3rd 21 female', prediction=0.0, probability=DenseVector([0.5212, 0.4788]))\n",
      "Row(PersonInfo=u'3rd 29 male', prediction=0.0, probability=DenseVector([0.9284, 0.0716]))\n",
      "Row(PersonInfo=u'3rd 22 male', prediction=0.0, probability=DenseVector([0.9155, 0.0845]))\n",
      "Row(PersonInfo=u'3rd 28 male', prediction=0.0, probability=DenseVector([0.9523, 0.0477]))\n",
      "Row(PersonInfo=u'3rd 10 female', prediction=0.0, probability=DenseVector([0.9658, 0.0342]))\n",
      "Row(PersonInfo=u'3rd 51 male', prediction=0.0, probability=DenseVector([0.9801, 0.0199]))\n",
      "Row(PersonInfo=u'3rd 21 male', prediction=0.0, probability=DenseVector([0.9471, 0.0529]))\n",
      "Row(PersonInfo=u'3rd 27 male', prediction=0.0, probability=DenseVector([0.9345, 0.0655]))\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test documents and print columns of interest\n",
    "prediction = model.transform(test)\n",
    "selected = prediction.select(\"PersonInfo\", \"prediction\", \"probability\")\n",
    "for row in selected.collect():\n",
    "    print row\n",
    "#for row in prediction.collect():\n",
    "#    print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|0.0       |90   |\n",
      "|1.0       |42   |\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tabulate the predicted outcome\n",
    "prediction.select(\"prediction\").groupBy(\"prediction\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|0.0  |80   |\n",
      "|1.0  |52   |\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tabulate the actual outcome\n",
    "prediction.select(\"label\").groupBy(\"label\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---+---+\n",
      "|label_prediction|0.0|1.0|\n",
      "+----------------+---+---+\n",
      "|             1.0| 21| 31|\n",
      "|             0.0| 69| 11|\n",
      "+----------------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This table shows:\n",
    "# 1. The number of survived passengers predicted as survived\n",
    "# 2. The number of survived passengers predicted as not survived\n",
    "# 3. The number of not survived passengers predicted as survived\n",
    "# 4. The number of not survived passengers predicted as not survived\n",
    "\n",
    "prediction.crosstab('label', 'prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluate_model\"></a>\n",
    "## Evaluate the Model\n",
    "\n",
    "We evaluate the model on a training set and on a test set.  The purpose is to measure the model's predictive accuracy, including the accuracy for new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Measure = 0.802348336595\n",
      "Training Accuracy = 0.838141025641\n",
      "Training Error = 0.161858974359\n",
      "Precision = 0.82\n",
      "Recall = 0.785440613027\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Logistic Regression model on a training set\n",
    "# Select (prediction, true label) and compute training error\n",
    "pred_lr=model.transform(train).select(\"prediction\", \"label\")\n",
    "eval_lr=MulticlassClassificationEvaluator (\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_lr=eval_lr.evaluate(pred_lr)\n",
    "# create RDD\n",
    "predictionAndLabels_lr=pred_lr.rdd\n",
    "metrics_lr=MulticlassMetrics(predictionAndLabels_lr)\n",
    "precision_lr=metrics_lr.precision(1.0)\n",
    "recall_lr=metrics_lr.recall(1.0)\n",
    "f1Measure_lr = metrics_lr.fMeasure(1.0, 1.0)\n",
    "print(\"F1 Measure = %s\" % f1Measure_lr)\n",
    "print (\"Training Accuracy = %s\" %accuracy_lr)\n",
    "print (\"Training Error = %s\" % (1-accuracy_lr))\n",
    "print (\"Precision = %s\" %precision_lr)\n",
    "print (\"Recall = %s\" %recall_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Measure = 0.659574468085\n",
      "Test Accuracy = 0.757575757576\n",
      "Test Error = 0.242424242424\n",
      "Precision = 0.738095238095\n",
      "Recall = 0.596153846154\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Logistic Regression model on a test set\n",
    "# Select (prediction, true label) and compute test error\n",
    "pred_lr=model.transform(test).select(\"prediction\", \"label\")\n",
    "eval_lr=MulticlassClassificationEvaluator (\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_lr=eval_lr.evaluate(pred_lr)\n",
    "# create RDD\n",
    "predictionAndLabels_lr=pred_lr.rdd\n",
    "metrics_lr=MulticlassMetrics(predictionAndLabels_lr)\n",
    "precision_lr=metrics_lr.precision(1.0)\n",
    "recall_lr=metrics_lr.recall(1.0)\n",
    "f1Measure_lr = metrics_lr.fMeasure(1.0, 1.0)\n",
    "print(\"F1 Measure = %s\" % f1Measure_lr)\n",
    "print (\"Test Accuracy = %s\" %accuracy_lr)\n",
    "print (\"Test Error = %s\" % (1-accuracy_lr))\n",
    "print (\"Precision = %s\" %precision_lr)\n",
    "print (\"Recall = %s\" %recall_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under PR = 0.74666999667\n",
      "Area under ROC = 0.729326923077\n"
     ]
    }
   ],
   "source": [
    "bin_lr=BinaryClassificationMetrics(predictionAndLabels_lr)\n",
    "\n",
    "# Area under precision-recall curve\n",
    "print(\"Area under PR = %s\" % bin_lr.areaUnderPR)\n",
    "# Area under precision-recall curve\n",
    "print(\"Area under ROC = %s\" % bin_lr.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.1",
   "language": "python",
   "name": "python2-spark21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "name": "machineLearningHAVCBluemix.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
